#!/usr/bin/env bats

# Test VM0 telemetry collection and retrieval
# This test verifies that:
# 1. Agent runs display Run ID at start
# 2. Agent runs collect telemetry data (system log and metrics)
# 3. The vm0 logs command can retrieve telemetry data
#
# Test count: 2 tests with 1 vm0 run call

load '../../helpers/setup'

# Unique agent name for this test file to avoid compose conflicts in parallel runs
AGENT_NAME="e2e-t15"

setup() {
    # Create unique volume for this test
    create_test_volume "e2e-vol-t15"

    export TEST_ARTIFACT_DIR="$(mktemp -d)"
    export ARTIFACT_NAME="e2e-telemetry-test-$(date +%s%3N)-$RANDOM"
    # Create inline config with unique agent name
    export TEST_CONFIG="$(mktemp --suffix=.yaml)"
    cat > "$TEST_CONFIG" <<EOF
version: "1.0"
agents:
  ${AGENT_NAME}:
    description: "E2E test agent for telemetry testing"
    framework: claude-code
    experimental_runner:
      group: ${RUNNER_GROUP}
    volumes:
      - claude-files:/home/user/.claude
    working_dir: /home/user/workspace
volumes:
  claude-files:
    name: $VOLUME_NAME
    version: latest
EOF
}

teardown() {
    if [ -n "$TEST_ARTIFACT_DIR" ] && [ -d "$TEST_ARTIFACT_DIR" ]; then
        rm -rf "$TEST_ARTIFACT_DIR"
    fi
    # Clean up config file
    if [ -n "$TEST_CONFIG" ] && [ -f "$TEST_CONFIG" ]; then
        rm -f "$TEST_CONFIG"
    fi
    # Clean up test volume
    cleanup_test_volume
}

@test "Build VM0 telemetry test agent configuration" {
    run $CLI_COMMAND compose "$TEST_CONFIG"
    assert_success
    assert_output --partial "$AGENT_NAME"
}

@test "VM0 telemetry: run displays Run ID and logs command retrieves data" {
    # Step 1: Create artifact with initial content
    echo "# Step 1: Creating initial artifact..."
    mkdir -p "$TEST_ARTIFACT_DIR/$ARTIFACT_NAME"
    cd "$TEST_ARTIFACT_DIR/$ARTIFACT_NAME"
    $CLI_COMMAND artifact init --name "$ARTIFACT_NAME" >/dev/null
    echo "test content" > test.txt
    run $CLI_COMMAND artifact push
    assert_success

    # Step 2: Run agent with a simple command
    echo "# Step 2: Running agent to trigger telemetry collection..."
    run $CLI_COMMAND run "$AGENT_NAME" \
        --artifact-name "$ARTIFACT_NAME" \
        "echo 'hello from agent'"

    assert_success

    # Verify "Run started" message with Run ID is displayed
    assert_output --partial "Run started"
    assert_output --partial "Run ID:"

    # Verify run completed successfully
    assert_output --partial "◆ Claude Code Completed"
    assert_output --partial "Run completed successfully"

    # Verify "vm0 logs" command hint is shown in next steps
    assert_output --partial "View agent logs:"
    assert_output --partial "vm0 logs"

    # Step 3: Extract Run ID from output
    # Format: "  Run ID:   abc12345-6789-..."
    RUN_ID=$(echo "$output" | grep -oP 'Run ID:\s+\K[a-f0-9-]{36}' | head -1)
    echo "# Run ID: $RUN_ID"
    [ -n "$RUN_ID" ] || {
        echo "# Failed to extract Run ID from output"
        echo "$output"
        return 1
    }

    # Step 4: Verify vm0 logs command (default: agent events)
    echo "# Step 4: Fetching agent events (default)..."
    run $CLI_COMMAND logs "$RUN_ID"

    assert_success

    # Default output shows agent events - verify event type markers are present
    # Mock-claude produces: Claude Code Started, text, tool calls, Completed
    assert_output --partial "▷ Claude Code Started"
    assert_output --partial "◆ Claude Code Completed"
    echo "# Agent events contain expected event types"

    # Step 5: Verify --agent option explicitly shows agent events
    echo "# Step 5: Testing --agent option..."
    run $CLI_COMMAND logs "$RUN_ID" --agent

    assert_success
    assert_output --partial "▷ Claude Code Started"
    echo "# --agent option works correctly"

    # Step 6: Verify --system option shows system logs
    echo "# Step 6: Testing --system option..."
    run $CLI_COMMAND logs "$RUN_ID" --system --tail 100

    assert_success
    # System log should contain sandbox log entries with INFO level
    # Format: [TIMESTAMP] [INFO] [sandbox:run-agent] message
    assert_output --partial "[INFO]"
    assert_output --partial "[sandbox:"
    echo "# System log contains expected log format"

    # Step 7: Verify --metrics option shows resource metrics
    echo "# Step 7: Testing --metrics option..."
    run $CLI_COMMAND logs "$RUN_ID" --metrics --tail 100

    assert_success
    # Metrics may take time to collect, so check if either:
    # 1. Metrics are available (contains CPU/Mem/Disk)
    # 2. Or "No metrics found" message is shown (acceptable for quick runs)
    if echo "$output" | grep -q "No metrics found"; then
        echo "# Metrics not yet available (acceptable for quick runs)"
    else
        # If metrics are available, verify format
        assert_output --partial "CPU:"
        assert_output --partial "Mem:"
        assert_output --partial "Disk:"
        echo "# Metrics contain expected resource data"
    fi

    # Step 8: Verify --tail option limits output
    echo "# Step 8: Testing --tail option..."
    run $CLI_COMMAND logs "$RUN_ID" --tail 2

    assert_success
    # With tail=2, should see at most 2 events
    # If more exist, should see "Use --tail to see more"
    echo "# Tail option works correctly"

    # Note: Mutually exclusive options validation (--agent, --system, etc.)
    # is tested in CLI integration tests:
    # turbo/apps/cli/src/commands/logs/__tests__/index.test.ts
    #   - "should exit with error when multiple log types specified"
}
