---
title: Model Selection
description: Configure different LLM providers for Claude Code in vm0.yaml
---

This guide explains how to configure different LLM providers for Claude Code using the `environment` field in your `vm0.yaml` configuration file.

## Overview

vm0 allows you to use various LLM providers that implement the Anthropic API. You can configure these providers by setting environment variables in your `vm0.yaml` file.

### Basic Structure

The `environment` field in `vm0.yaml` accepts key-value pairs for environment variables:

```yaml
version: "1.0"

agents:
  my-agent:
    provider: claude-code
    environment:
      ANTHROPIC_BASE_URL: "https://api.example.com/anthropic"
      ANTHROPIC_AUTH_TOKEN: "${{ secrets.API_KEY }}"
      ANTHROPIC_MODEL: "model-name"
```

You can use template variables to reference secrets:

- `${{ secrets.SECRET_NAME }}` - References a secret variable
- `${{ vars.varName }}` - References a regular variable

## Supported Providers

### Moonshot (Kimi)

[Moonshot](https://platform.moonshot.ai/docs/guide/agent-support) provides the Kimi K2 model with strong reasoning capabilities.

```yaml
version: "1.0"

agents:
  kimi-agent:
    provider: claude-code
    environment:
      ANTHROPIC_BASE_URL: "https://api.moonshot.ai/anthropic"
      ANTHROPIC_AUTH_TOKEN: "${{ secrets.MOONSHOT_API_KEY }}"
      ANTHROPIC_MODEL: "kimi-k2-thinking-turbo"
      ANTHROPIC_DEFAULT_OPUS_MODEL: "kimi-k2-thinking-turbo"
      ANTHROPIC_DEFAULT_SONNET_MODEL: "kimi-k2-thinking-turbo"
      ANTHROPIC_DEFAULT_HAIKU_MODEL: "kimi-k2-thinking-turbo"
      CLAUDE_CODE_SUBAGENT_MODEL: "kimi-k2-thinking-turbo"
```

**Available Models:**

- `kimi-k2-thinking-turbo` - Fast reasoning model

### MiniMax

[MiniMax](https://platform.minimax.io/docs/guides/text-ai-coding-tools) offers the M2.1 model with strong code understanding and multi-turn dialogue capabilities.

```yaml
version: "1.0"

agents:
  minimax-agent:
    provider: claude-code
    environment:
      ANTHROPIC_BASE_URL: "https://api.minimax.io/anthropic"
      ANTHROPIC_AUTH_TOKEN: "${{ secrets.MINIMAX_API_KEY }}"
      API_TIMEOUT_MS: "3000000"
      CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC: "1"
      ANTHROPIC_MODEL: "MiniMax-M2.1"
      ANTHROPIC_SMALL_FAST_MODEL: "MiniMax-M2.1"
      ANTHROPIC_DEFAULT_SONNET_MODEL: "MiniMax-M2.1"
      ANTHROPIC_DEFAULT_OPUS_MODEL: "MiniMax-M2.1"
      ANTHROPIC_DEFAULT_HAIKU_MODEL: "MiniMax-M2.1"
```

**Regional Endpoints:**

- International: `https://api.minimax.io/anthropic`
- China: `https://api.minimaxi.com/anthropic`

**Available Models:**

- `MiniMax-M2.1` - Code understanding and reasoning model

### DeepSeek

[DeepSeek](https://api-docs.deepseek.com/guides/anthropic_api) provides cost-effective models with strong coding capabilities.

```yaml
version: "1.0"

agents:
  deepseek-agent:
    provider: claude-code
    environment:
      ANTHROPIC_BASE_URL: "https://api.deepseek.com/anthropic"
      ANTHROPIC_AUTH_TOKEN: "${{ secrets.DEEPSEEK_API_KEY }}"
      API_TIMEOUT_MS: "600000"
      CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC: "1"
      ANTHROPIC_MODEL: "deepseek-chat"
      ANTHROPIC_SMALL_FAST_MODEL: "deepseek-chat"
```

**Available Models:**

- `deepseek-chat` - General purpose chat model (default mapping for all models)

### Z.AI (GLM)

[Z.AI](https://docs.z.ai/devpack/tool/claude) provides access to GLM models with strong coding capabilities.

```yaml
version: "1.0"

agents:
  zai-agent:
    provider: claude-code
    environment:
      ANTHROPIC_BASE_URL: "https://api.z.ai/api/anthropic"
      ANTHROPIC_AUTH_TOKEN: "${{ secrets.ZAI_API_KEY }}"
      API_TIMEOUT_MS: "3000000"
      ANTHROPIC_DEFAULT_OPUS_MODEL: "GLM-4.7"
      ANTHROPIC_DEFAULT_SONNET_MODEL: "GLM-4.7"
      ANTHROPIC_DEFAULT_HAIKU_MODEL: "GLM-4.5-Air"
```

**Available Models:**

- `GLM-4.7` - High-performance coding model
- `GLM-4.5-Air` - Fast, lightweight model

Get your API key at [Z.AI Open Platform](https://z.ai/model-api).

### OpenRouter

[OpenRouter](https://openrouter.ai/docs/guides/guides/claude-code-integration) provides access to multiple model providers through a unified API, allowing you to use models from OpenAI, Anthropic, and others.

```yaml
version: "1.0"

agents:
  openrouter-agent:
    provider: claude-code
    environment:
      ANTHROPIC_BASE_URL: "https://openrouter.ai/api"
      ANTHROPIC_AUTH_TOKEN: "${{ secrets.OPENROUTER_API_KEY }}"
      ANTHROPIC_API_KEY: ""
      ANTHROPIC_DEFAULT_SONNET_MODEL: "anthropic/claude-sonnet-4"
      ANTHROPIC_DEFAULT_OPUS_MODEL: "anthropic/claude-opus-4"
      ANTHROPIC_DEFAULT_HAIKU_MODEL: "anthropic/claude-haiku-3.5"
```

**Important:** `ANTHROPIC_API_KEY` must be explicitly set to an empty string to prevent conflicts.

**Popular Model Examples:**

- `anthropic/claude-sonnet-4` - Claude Sonnet 4
- `anthropic/claude-opus-4` - Claude Opus 4
- `openai/gpt-4o` - GPT-4o
- `google/gemini-2.5-pro` - Gemini 2.5 Pro

Browse all available models at [OpenRouter Models](https://openrouter.ai/models).

## Environment Variables Reference

| Variable                                   | Description                                            |
| ------------------------------------------ | ------------------------------------------------------ |
| `ANTHROPIC_BASE_URL`                       | API endpoint URL for the provider                      |
| `ANTHROPIC_AUTH_TOKEN`                     | API key for authentication                             |
| `ANTHROPIC_API_KEY`                        | Set to empty string when using non-Anthropic providers |
| `ANTHROPIC_MODEL`                          | Primary model to use                                   |
| `ANTHROPIC_DEFAULT_OPUS_MODEL`             | Model for Opus-tier tasks                              |
| `ANTHROPIC_DEFAULT_SONNET_MODEL`           | Model for Sonnet-tier tasks                            |
| `ANTHROPIC_DEFAULT_HAIKU_MODEL`            | Model for Haiku-tier tasks (fast, lightweight)         |
| `ANTHROPIC_SMALL_FAST_MODEL`               | Model for quick, simple tasks                          |
| `CLAUDE_CODE_SUBAGENT_MODEL`               | Model for subagent tasks                               |
| `API_TIMEOUT_MS`                           | Request timeout in milliseconds                        |
| `CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC` | Set to `1` to reduce unnecessary API calls             |

## Using Secrets

Store your API keys as secrets and reference them in your configuration:

```yaml
environment:
  ANTHROPIC_AUTH_TOKEN: "${{ secrets.MY_API_KEY }}"
```

Pass the secret value when running via environment variable or CLI flag:

```bash
# Via environment variable
export MY_API_KEY=sk-your-actual-api-key
vm0 run my-agent "your prompt"

# Via CLI flag
vm0 run my-agent "your prompt" --secrets MY_API_KEY=sk-your-actual-api-key
```

For more details on secrets and variables, see the [Environment Variables](/docs/environment-variables) guide.
