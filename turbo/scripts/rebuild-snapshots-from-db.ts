#!/usr/bin/env tsx

/**
 * Script to rebuild Drizzle snapshot chain from database state
 *
 * This script rebuilds missing snapshots by:
 * 1. Creating a temporary database
 * 2. Starting from the last valid snapshot (0015)
 * 3. Applying each migration SQL sequentially
 * 4. Using drizzle-kit introspect to generate snapshot from actual DB state
 * 5. Saving the snapshot with the correct migration number
 *
 * This approach is more reliable than checking out old commits because:
 * - It uses the actual migration SQL that was applied
 * - It doesn't depend on schema files being in sync at commit time
 * - It reflects the true database state after each migration
 *
 * Prerequisites:
 * - PostgreSQL server running
 * - DATABASE_URL environment variable set
 *
 * Usage:
 *   pnpm tsx scripts/rebuild-snapshots-from-db.ts [start-idx] [end-idx]
 *
 * Examples:
 *   pnpm tsx scripts/rebuild-snapshots-from-db.ts          # Rebuild all (16-88)
 *   pnpm tsx scripts/rebuild-snapshots-from-db.ts 16 20    # Rebuild 16-20
 */

import { execSync } from "child_process";
import { randomUUID } from "crypto";
import fs from "fs";
import path from "path";
import { Pool } from "pg";

const MIGRATIONS_DIR = path.join(__dirname, "../apps/web/src/db/migrations");
const META_DIR = path.join(MIGRATIONS_DIR, "meta");
const TEMP_DB_NAME = `snapshot_rebuild_${Date.now()}`;

interface MigrationInfo {
  idx: number;
  tag: string;
  sqlFile: string;
  sqlPath: string;
}

function exec(
  command: string,
  options?: { silent?: boolean; cwd?: string },
): string {
  try {
    return execSync(command, {
      encoding: "utf-8",
      stdio: options?.silent ? "pipe" : "inherit",
      cwd: options?.cwd,
    });
  } catch (error) {
    if (options?.silent) {
      return "";
    }
    throw error;
  }
}

function getMigrationList(startIdx: number, endIdx: number): MigrationInfo[] {
  const files = fs
    .readdirSync(MIGRATIONS_DIR)
    .filter((f) => f.endsWith(".sql"))
    .sort();

  const migrations: MigrationInfo[] = [];

  for (const file of files) {
    const match = file.match(/^(\d{4})_(.+)\.sql$/);
    if (!match) continue;

    const idx = parseInt(match[1], 10);
    if (idx < startIdx || idx > endIdx) continue;

    const tag = `${match[1]}_${match[2]}`;

    migrations.push({
      idx,
      tag,
      sqlFile: file,
      sqlPath: path.join(MIGRATIONS_DIR, file),
    });
  }

  return migrations;
}

async function createTempDatabase(adminPool: Pool): Promise<string> {
  console.log(`üîß Creating temporary database: ${TEMP_DB_NAME}`);
  await adminPool.query(`CREATE DATABASE ${TEMP_DB_NAME}`);
  return TEMP_DB_NAME;
}

async function dropTempDatabase(adminPool: Pool) {
  console.log(`üóëÔ∏è  Dropping temporary database: ${TEMP_DB_NAME}`);
  await adminPool.query(`DROP DATABASE IF EXISTS ${TEMP_DB_NAME}`);
}

async function applyMigration(pool: Pool, migration: MigrationInfo) {
  console.log(`üìù Applying migration: ${migration.tag}`);
  const sql = fs.readFileSync(migration.sqlPath, "utf-8");

  // Remove --> statement-breakpoint comments
  const cleanSql = sql.replace(/--> statement-breakpoint/g, "");

  // Execute the entire SQL at once (PostgreSQL can handle multiple statements)
  await pool.query(cleanSql);
}

async function generateSnapshotFromDb(
  tempDbUrl: string,
  migration: MigrationInfo,
): Promise<boolean> {
  console.log(`üì∏ Generating snapshot for ${migration.tag}...`);

  const INTROSPECT_DIR = path.join(
    "/tmp",
    `snapshot_introspect_${migration.idx}`,
  );

  try {
    // Clear introspect directory
    if (fs.existsSync(INTROSPECT_DIR)) {
      fs.rmSync(INTROSPECT_DIR, { recursive: true });
    }
    fs.mkdirSync(INTROSPECT_DIR, { recursive: true });

    // Run drizzle-kit introspect to generate snapshot from database state
    console.log("üîç Introspecting database...");
    const webDir = path.join(__dirname, "../apps/web");
    exec(
      `pnpm drizzle-kit introspect --dialect=postgresql --url="${tempDbUrl}" --out="${INTROSPECT_DIR}"`,
      { silent: false, cwd: webDir },
    );

    // The introspect command generates meta/0000_snapshot.json
    const introspectSnapshot = path.join(
      INTROSPECT_DIR,
      "meta",
      "0000_snapshot.json",
    );
    if (!fs.existsSync(introspectSnapshot)) {
      console.error("‚ùå No snapshot generated by introspect");
      return false;
    }

    // Read the generated snapshot and update its metadata
    const snapshotContent = JSON.parse(
      fs.readFileSync(introspectSnapshot, "utf-8"),
    );

    // Update prevId to link to previous snapshot
    if (migration.idx > 0) {
      const prevSnapshotPath = path.join(
        META_DIR,
        `${String(migration.idx - 1).padStart(4, "0")}_snapshot.json`,
      );

      if (fs.existsSync(prevSnapshotPath)) {
        const prevSnapshot = JSON.parse(
          fs.readFileSync(prevSnapshotPath, "utf-8"),
        );
        snapshotContent.prevId = prevSnapshot.id;
      }
    }

    // Generate new UUID for this snapshot
    snapshotContent.id = randomUUID();

    // Write to correct location
    const expectedName = `${String(migration.idx).padStart(4, "0")}_snapshot.json`;
    const targetPath = path.join(META_DIR, expectedName);

    fs.writeFileSync(
      targetPath,
      JSON.stringify(snapshotContent, null, 2) + "\n",
    );
    console.log(`‚úÖ Created snapshot: ${expectedName}`);

    // Update _journal.json to ensure this migration entry exists
    const journalPath = path.join(META_DIR, "_journal.json");
    const journal = JSON.parse(fs.readFileSync(journalPath, "utf-8"));

    // Check if entry already exists
    const existingEntry = journal.entries.find(
      (e: any) => e.idx === migration.idx,
    );
    if (!existingEntry) {
      console.log(
        `‚ö†Ô∏è  Migration ${migration.idx} not in journal - this shouldn't happen`,
      );
    }

    fs.writeFileSync(journalPath, JSON.stringify(journal, null, 2) + "\n");

    // Clean up introspect directory
    fs.rmSync(INTROSPECT_DIR, { recursive: true });

    return true;
  } catch (error) {
    console.error(`‚ùå Error generating snapshot: ${error}`);

    // Clean up on error
    if (fs.existsSync(INTROSPECT_DIR)) {
      fs.rmSync(INTROSPECT_DIR, { recursive: true });
    }

    return false;
  }
}

async function restoreSnapshotState(
  pool: Pool,
  snapshotIdx: number,
): Promise<boolean> {
  if (snapshotIdx < 0) {
    console.log("üì¶ Starting from empty database (no migrations to restore)");
    return true;
  }

  console.log(`üì¶ Restoring database to migration ${snapshotIdx}...`);

  // Apply all migrations from 0000 to snapshotIdx
  const migrations = getMigrationList(0, snapshotIdx);

  for (const migration of migrations) {
    await applyMigration(pool, migration);
  }

  return true;
}

async function main() {
  const args = process.argv.slice(2);
  const startIdx = args[0] ? parseInt(args[0], 10) : 16;
  const endIdx = args[1] ? parseInt(args[1], 10) : 88;

  console.log("üöÄ Drizzle Snapshot Rebuilder");
  console.log("=".repeat(80));

  const databaseUrl = process.env.DATABASE_URL;
  if (!databaseUrl) {
    console.error("‚ùå DATABASE_URL environment variable not set");
    process.exit(1);
  }

  // Parse database URL to get admin connection
  const url = new URL(databaseUrl);
  const adminDbUrl = `postgresql://${url.username}:${url.password}@${url.host}/postgres`;

  const adminPool = new Pool({ connectionString: adminDbUrl });

  try {
    // Create temp database
    await createTempDatabase(adminPool);

    const tempDbUrl = `postgresql://${url.username}:${url.password}@${url.host}/${TEMP_DB_NAME}`;
    const tempPool = new Pool({ connectionString: tempDbUrl });

    try {
      // Restore to the migration before the first one we need to process
      const restoreToIdx = startIdx - 1;
      if (restoreToIdx >= 0) {
        console.log(`\nüì¶ Restoring to migration ${restoreToIdx}...`);
      }
      await restoreSnapshotState(tempPool, restoreToIdx);

      // Get migrations to process
      const migrations = getMigrationList(startIdx, endIdx);
      console.log(
        `\nüìã Processing ${migrations.length} migrations (${startIdx}-${endIdx})`,
      );

      const results = {
        success: 0,
        failed: 0,
      };

      for (const migration of migrations) {
        console.log(`\n${"=".repeat(80)}`);

        // Apply migration to temp database
        await applyMigration(tempPool, migration);

        // Generate snapshot from database state
        const success = await generateSnapshotFromDb(tempDbUrl, migration);

        if (success) {
          results.success++;
        } else {
          results.failed++;
          console.error(`‚ùå Failed to generate snapshot for ${migration.tag}`);
          // Continue with next migration
        }
      }

      console.log("\n" + "=".repeat(80));
      console.log("üìä Summary");
      console.log("=".repeat(80));
      console.log(`‚úÖ Success: ${results.success}`);
      console.log(`‚ùå Failed: ${results.failed}`);
      console.log("=".repeat(80));
    } finally {
      await tempPool.end();
    }
  } finally {
    // Cleanup
    await dropTempDatabase(adminPool);
    await adminPool.end();
  }
}

main().catch((error) => {
  console.error("Fatal error:", error);
  process.exit(1);
});
